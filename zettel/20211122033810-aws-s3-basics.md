# AWS S3 Basics

S3 is simple, scalable, object storage. It manages data as objects rather than in file systems or data blocks. Meaning in can really support any data type, but not an OS or database storage.

Unlimited storage, with a max file size of 5TB.

Files are stored in **buckets**, which are similar to folders. These share a universal namespace so each bucket name has to be globally unique. Buckets are regional, depsite the AWS console view being global.

Data is spread across multiple devices and facilities to ensure availability and durability.

The default storage class is designed for frequent access, and supports most workloads, but is the most expensive. 'Glacier' exists for long-term archival. Lifecycle management automates moving objets between storage classes for cost effectiveness.

Different ways to secure your data: server-side encryption, access control lists (individual object level), bucket policies (bucket-wide).

Strong read-after-write consistency.

Can be useful for hosting static sites as it scales automatically - just need to set the entire bucket to public.

Optional versioning. Once enabled, can only be suspended. Deleting an object will create a 'delete marker', with all the versions underneath it. Deleting the delete marker will restore the older version. Also supports MFA to help stop deletions.

The prefixes S3 URLs use are just the folders in your bucket. Since the max requests per second are per prefix, you can achieve greater performance by spreading data across prefixes.

Multipart uploads are recommended for files over 100mb, and required for files over 5gb.

[[aws]]